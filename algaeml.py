# -*- coding: utf-8 -*-
"""AlgaeML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pD3C5yWrBs-OZStQhnrxvJTLGqZ6lsLQ

**ML Implementation**

In this phase, machine learning methods are applied to the datasets. The COIL dataset was selected for modeling because it represents real environmental conditions, making it more suitable for predictive analysis and scientifically meaningful interpretation compared to a controlled laboratory dataset.

Two main tasks will be completed in the notebook:
1.   Generating an ML model to predict "mean_chlorophyll"
2.   Generating an ML model to predict mean of frequencies of algae groups

The results of these two models are compared to evaluate how machine learning performance differs when predicting two types of biological outcomes: a biochemical indicator (chlorophyll concentration) versus a community level biological measure (mean algal abundance). It is expected that models will perform better when predicting chlorophyll, since the input features consist of physicochemical parameters that are more directly associated with biomass-related indicators than with aggregated biological population measures.
"""

import pandas as pd
import numpy as np
df_coil_processed = pd.read_csv('/content/df_coil_processed.csv')
df_coil_processed

"""**Feature Engineering**

We have some important categorical variables, let's convert them to numericals.
"""

df_coil_encoded = pd.get_dummies(df_coil_processed, columns=['Season', 'Size', 'River_Size'], drop_first=False, dtype=int)
df_coil_encoded

"""Let's also add the mean frequency feature in the dataframe."""

algae_group_columns = [col for col in df_coil_encoded.columns if col.startswith('Algae_Group_')]
df_coil_encoded['mean_freq'] = df_coil_encoded[algae_group_columns].mean(axis=1)
df_coil_encoded = df_coil_encoded.drop(columns=algae_group_columns)
df_coil_encoded

"""Let's prepare the data for ML, final step before execution."""

X = df_coil_encoded.drop(columns=['Mean_Chlorophyll', 'mean_freq'])
y1 = df_coil_encoded['Mean_Chlorophyll']
y2 = df_coil_encoded['mean_freq']

"""**ML Models**

I will try both targets with 3 ML models: linear regression, nearest neighbor and random forest.

I will use K Folds since the data is fairly smaller. All models will perform on the same folds which will enable reliable comparative analysis.
"""

from sklearn.model_selection import KFold
kf = KFold(n_splits=5, shuffle=True, random_state=42)

from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

models = []

models.append((
    'Linear Regression',
    Pipeline([
        ('scaler', StandardScaler()),
        ('regressor', LinearRegression())
    ])
))

models.append((
    'K-Neighbors Regressor',
    Pipeline([
        ('scaler', StandardScaler()),
        ('regressor', KNeighborsRegressor())
    ])
))

models.append((
    'Random Forest Regressor',
    RandomForestRegressor(random_state=42)
))

from sklearn.model_selection import cross_validate, cross_val_predict

all_results = []

scoring = {
    'r2': 'r2',
    'rmse': 'neg_root_mean_squared_error',
    'mae': 'neg_mean_absolute_error'
}

targets = [
    ('Mean_Chlorophyll', y1),
    ('mean_freq', y2)
]

for target_name, y in targets:
    for model_name, model in models:
        cv_results = cross_validate(
            model, X, y, cv=kf, scoring=scoring, return_train_score=False
        )
        y_predicted = cross_val_predict(model, X, y, cv=kf)

        all_results.append({
            'target': target_name,
            'model': model_name,
            'scores': cv_results,
            'y_actual': y.values,
            'y_predicted': y_predicted
        })

all_results

"""I have all the relevant test results, time to format them for readable table."""

formatted_results = []

for result in all_results:
    target_name = result['target']
    model_name = result['model']
    scores = result['scores']

    r2_scores = scores['test_r2']
    rmse_scores = scores['test_rmse'] * -1
    mae_scores = scores['test_mae'] * -1

    mean_r2 = np.mean(r2_scores)
    std_r2 = np.std(r2_scores)

    mean_rmse = np.mean(rmse_scores)
    std_rmse = np.std(rmse_scores)

    mean_mae = np.mean(mae_scores)
    std_mae = np.std(mae_scores)

    formatted_results.append({
        'target': target_name,
        'model': model_name,
        'mean_R2': mean_r2,
        'std_R2': std_r2,
        'mean_RMSE': mean_rmse,
        'std_RMSE': std_rmse,
        'mean_MAE': mean_mae,
        'std_MAE': std_mae
    })

results_df = pd.DataFrame(formatted_results)
results_df

"""As depicted by the dataframe above, ML models performed better for chlorophyll target, as expected. Random Forest was the best performer with 47% accuracy for chlorophyll with low variation of 6%; which is very reasonable since the biological settings are very variable and cannot be explained by simple linear relationships. For alge group mean all ML models were underperformed around 10-20% with relatively higher variances.

The results validated the initial expectation for chloropyll, as a direct biochemical variable, is a better target for ML modelling with biochemical features.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Find the results for Random Forest Regressor for Mean_Chlorophyll
rf_chlorophyll_results = next(item for item in all_results if item['target'] == 'Mean_Chlorophyll' and item['model'] == 'Random Forest Regressor')

# Extract actual and predicted values
y_actual_chlorophyll = rf_chlorophyll_results['y_actual']
y_predicted_chlorophyll = rf_chlorophyll_results['y_predicted']

# Create scatter plot for Mean_Chlorophyll
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_actual_chlorophyll, y=y_predicted_chlorophyll, alpha=0.7)
plt.plot([min(y_actual_chlorophyll), max(y_actual_chlorophyll)], [min(y_actual_chlorophyll), max(y_actual_chlorophyll)], 'r--', lw=2) # Line for perfect prediction
plt.title('Predicted vs. Actual Mean_Chlorophyll (Random Forest Regressor)')
plt.xlabel('Actual Mean_Chlorophyll')
plt.ylabel('Predicted Mean_Chlorophyll')
plt.grid(True)
plt.show()

rf_mean_freq_results = next(item for item in all_results if item['target'] == 'mean_freq' and item['model'] == 'Random Forest Regressor')

y_actual_mean_freq = rf_mean_freq_results['y_actual']
y_predicted_mean_freq = rf_mean_freq_results['y_predicted']

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_actual_mean_freq, y=y_predicted_mean_freq, alpha=0.7)
plt.plot([min(y_actual_mean_freq), max(y_actual_mean_freq)], [min(y_actual_mean_freq), max(y_actual_mean_freq)], 'r--', lw=2) # Line for perfect prediction
plt.title('Predicted vs. Actual Mean Frequency (Random Forest Regressor)')
plt.xlabel('Actual Mean Frequency')
plt.ylabel('Predicted Mean Frequency')
plt.grid(True)
plt.show()